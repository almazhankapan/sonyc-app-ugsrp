{"ast":null,"code":"var _jsxFileName = \"/Users/almazhan/Desktop/sonyc-app-ugsrp/src/pages/DataVisualization.js\";\nimport React from 'react';\nimport Header from '../components/Header';\nimport Footer from '../components/Footer';\nimport lit1 from '../images/lit1.png';\nimport lit2 from '../images/lit2.png';\nimport lit3 from '../images/lit3.png';\nimport lit4 from '../images/lit4.png';\nimport lit5 from '../images/lit5.png';\nimport lit1a from '../images/lit1a.png';\nimport lit2a from '../images/lit2a.png';\nimport granular from '../images/granular.png';\nimport './DataVisualization.css';\nimport Collapsible from 'react-collapsible';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nfunction DataVisualization() {\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [/*#__PURE__*/_jsxDEV(Header, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"home\",\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        className: \"header-text\",\n        children: \"Data Visualization\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 20,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"block\",\n        children: [/*#__PURE__*/_jsxDEV(\"p\", {\n          className: \"full-text\",\n          children: \"Sensors are used to measure air and noise pollution levels and visualizing the data is the first step in making decisions about the data.\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 22,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 27,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 21,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"block\",\n        children: [/*#__PURE__*/_jsxDEV(\"h4\", {\n          className: \"gif-text\",\n          children: \"Data Visualization Research Review\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 30,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          children: [/*#__PURE__*/_jsxDEV(\"p\", {\n            className: \"full-text\",\n            children: [/*#__PURE__*/_jsxDEV(\"b\", {\n              children: [' ', \"Guess the Data: Data Work to Understand How People Make Sense of and Use Simple Sensor Data from Homes .Albrecht Kurze, Andreas Bischof, S\\xF6ren Totzauer, Michael Storz, Maximilian Eibl, Margot Brereton, and Arne Berger. 2020.\"]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 34,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 41,\n              columnNumber: 15\n            }, this), \". Association for Computing Machinery, New York, NY, USA, 1\\u201312. DOI:https://doi.org/10.1145/3313831.3376273\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 33,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n            trigger: \"Read More\",\n            className: \"full-text\",\n            children: [/*#__PURE__*/_jsxDEV(\"p\", {\n              className: \"full-text\",\n              children: [\"The authors investigate human sensemaking of such sensor data can reveal domestic activities and to achieve that task, develop and field-test the Guess the data method,which enabled people to use and make sense of live data from their homes and to collectively interpret and reflect on anonymized data from the homes in the study. The authors decided to use simple line graphs as data visualizations for temperature, light level, humidity, barometric pressure and movement (accelerometer values). They wanted to undertake very little pre-processing, presenting close to \\u2018raw\\u2019 data, to prevent interpretation bias. Such simple time series graphs are comparable to those used in other cited studies. The findings show how participants reconstruct behavior, both individually and collectively, expose the sensitive personal data of others, and use sensor data as evidence and for lateral surveillance within the household.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 65,\n                columnNumber: 17\n              }, this), \"Visualized sensor data used as evidence and proof: Participants used visualized data to confirm their assumptions about other residents\\u2019 behavior, not only retrospectively during discussions but also pro-actively during data collection when they had access to it. For example, a participant corrected the partner\\u2019s careless behavior regarding the light in the hallway (figure 3), which he often forgot to turn off. She confronted him with the visualization of the light sensor data, and \\u201Che was a little bit shocked\\u201D (II.A)\"]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 49,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n              src: lit1,\n              alt: \"poster gif\",\n              className: \"vis-img\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 76,\n              columnNumber: 15\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 48,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 78,\n            columnNumber: 13\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 32,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          children: [/*#__PURE__*/_jsxDEV(\"p\", {\n            className: \"full-text\",\n            children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 83,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n              children: \"Nicolas Maisonneuve, Matthias Stevens, Maria E. Niessen, Peter Hanappe, and Luc Steels. 2009. Citizen noise pollution monitoring.\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 84,\n              columnNumber: 15\n            }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"Proceedings of the 10th Annual International Conference on Digital Government Research: Social Networks: Making Connections between Citizens, Data and Government\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 90,\n              columnNumber: 15\n            }, this), ' ', \"(\", /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"dg.o '09\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 95,\n              columnNumber: 16\n            }, this), \"). Digital Government Society of North America, 96\\u2013103. https://dl.acm.org/doi/10.5555/1556176.1556198\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 82,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n            trigger: \"Read More\",\n            className: \"full-text\",\n            children: /*#__PURE__*/_jsxDEV(\"p\", {\n              className: \"full-text\",\n              children: [\"In this paper, authors present a new approach to monitor noise pollution involving citizens who can measure their personal exposure to noise in their everyday environment by using GPS-equipped mobile phones as noise sensors. The geo-localised measures and user-generated meta-data can be automatically sent and shared online with the public to contribute to the collective noise mapping of cities. The prototype called Noise Tube can be found online. This application collects local information from different sensors (noise level, GPS coordinates, time, user input) and sends them to the NoiseTube server which visualizes the noise level data. The server centralises and processes the data sent by the phones.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 112,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 113,\n                columnNumber: 17\n              }, this), \"The mobile application contains a real-time signal processing algorithm which measures the loudness level of the microphone recording the environmental sound (at 22500 Hz, 16 bits) over 1 second at a chosen interval. On top of the sensing of the loudness a real time visualization is displayed on the phone with the decibels. To add meaning to this value it is associated with a colour that represents the health risk of the current exposure level: less than 70: green (no risk); between 70 and 80: yellow (be careful); more than 80: red (risky). See figure 2 below.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 124,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 125,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: lit2,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 126,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 127,\n                columnNumber: 17\n              }, this), \"In addition to measured loudness, the app allows to record the source or context of noise, which is not always available but remains important. Especially because the appreciation of sound and loudness is a subjective matter \\u2013 i.e. the perceived annoyance (or pleasure) does not always correlate with its loudness (see 6.2). Context is recorded through environmental tagging (source of a noise e.g.: cars, aircraft, neighbours and an annoyance rating/tag) and geo-tagging (gps positioning or place tags (such as \\u201Chome\\u201D, \\u201Cwork\\u201D, the name of the subway station, ...) Geo-tagging feature we can reconstruct the geo-coordinates afterwards notably for indoor locations (cf. subway noise map in figure 3).\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 140,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: lit3,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 141,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 142,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 143,\n                columnNumber: 17\n              }, this), \"Visualising Noise Maps. Once the measured data is sent to the server, any user can see his own contributions or exposures by going to the NoiseTube website and visualizing them on a map thanks to Google Earth. The collective noise map is also publicly available constructed by aggregating all the shared participants. Each map can show a layer of participants to add context and meaning to the loudness data. The authors also allow users embed this as a web widget into their personal web pages and provide publicly accessible web API to give full access to third parties such scientists or developers can use individual or collective exposure data to create web mash-ups or analyse data for scientific purposes.\"]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 99,\n              columnNumber: 15\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 98,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 158,\n            columnNumber: 13\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 81,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          children: [/*#__PURE__*/_jsxDEV(\"p\", {\n            className: \"full-text\",\n            children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 162,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n              children: [\"Silvia Santini, Benedikt Ostermaier, and Andrea Vitaletti. 2008. First experiences using wireless sensor networks for noise pollution monitoring.\", ' ']\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 163,\n              columnNumber: 15\n            }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"Proceedings of the workshop on Real-world wireless sensor networks\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 169,\n              columnNumber: 15\n            }, this), ' ', \"(\", /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"REALWSN '08\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 173,\n              columnNumber: 16\n            }, this), \"). Association for Computing Machinery, New York, NY, USA, 61\\u201365. DOI:https://doi.org/10.1145/1435473.1435490\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 161,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n            trigger: \"Read More\",\n            className: \"full-text\",\n            children: /*#__PURE__*/_jsxDEV(\"p\", {\n              className: \"full-text\",\n              children: [\"The authors focus on the assessment of environmental noise pollution in urban areas and provide a feasibility analysis of wireless sensor networks. They also present a prototype for the collection and logging of noise pollution data based on the Tmote invent prototyping platform, using which they performed indoor and outdoor noise pollution measurements. They also present tinyLAB, a Matlab-based tool developed in the context of this work, which enables real-time acquisition, processing and visualization of data collected in wireless sensor networks. Authors mention that prototyping wireless sensor network applications often requires visualizing the sensor data to quickly identify any malfunctioning. For example, figure 1 shows the responses to these acoustic events of four different nodes, clearly pointing out a misalignment in the measured equivalent noise levels. \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 192,\n                columnNumber: 31\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 193,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: lit4,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 194,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 195,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 196,\n                columnNumber: 17\n              }, this), \"Additionally, authors mention that current tools often do not provide satisfactory data processing and visualization features and propose using Matlab as it serves scientists in managing, processing and visualizing their data and appears therefore particularly well-suited to be used in the context of wireless sensor networks. Authors develop tinyLAB, a simple framework that allows to receive and send messages from and to a sensor network and to visualize and process data as it comes from the network. tinyLAB is implemented relying solely on the Matlab software suite and offers a simple API to receive and send data.\"]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 177,\n              columnNumber: 15\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 176,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 209,\n            columnNumber: 13\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 160,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          children: [/*#__PURE__*/_jsxDEV(\"p\", {\n            className: \"full-text\",\n            children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 213,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n              children: [\"Ann-sofie Gunnarsson, Malinda Rauhala, Anders Henrysson, and Anders Ynnerman. 2006. Visualization of sensor data using mobile phone augmented reality.\", ' ']\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 214,\n              columnNumber: 15\n            }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"Proceedings of the 5th IEEE and ACM International Symposium on Mixed and Augmented Reality\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 220,\n              columnNumber: 15\n            }, this), ' ', \"(\", /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"ISMAR '06\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 224,\n              columnNumber: 16\n            }, this), \"). IEEE Computer Society, USA, 233\\u2013234. DOI:https://doi.org/10.1109/ISMAR.2006.297820\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 212,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n            trigger: \"Read More\",\n            className: \"full-text\",\n            children: /*#__PURE__*/_jsxDEV(\"p\", {\n              className: \"full-text\",\n              children: [\"The authors developed a prototype system for visual inspection of hidden structures using a mobile phone wireless ZigBee sensor network. Data collected from an embedded wireless sensor matrix is used to synthesize AR visualizations in real-time. The AR visualization is providing the user with an instant insight concerning the status of the element being augmented. The authors arrange sensors in a grid (e.g. a matrix), which allows to take an approach where individual sensors emerge as pixels in an image when their data is translated into color values. See below an image that shows a mobile application overview.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 239,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 240,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: lit5,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 241,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 242,\n                columnNumber: 17\n              }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 242,\n                columnNumber: 24\n              }, this), \"Authors argue that AR is an ideal way to present such context related visualizations since it eliminates the focus switching between the visualization domain (image) and problem domain (real world). The sensors measure the relative humidity (RH) at the location of the sensor, providing with data from a discrete set of measure points in 3D. The values between the measure points are interpolated creating a continuous visualization which provides the user an overview of the humidity values as well as their distribution. The mobile phone application contains a visualization engine and a communication layer. The interpolation is performed in real time and every time a new sensor value is retrieved from the sensor network the visualization is updated. Two visualization options are implemented, one fully continuous, see Figure below, while the other is composed of small quadratic units, separated using full transparency. Authors believe that the user experiences a better sense of orientation when less background information is covered by the visualization.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 261,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 228,\n              columnNumber: 15\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 227,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 264,\n            columnNumber: 13\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 211,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          children: [/*#__PURE__*/_jsxDEV(\"p\", {\n            className: \"full-text\",\n            children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 269,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n              children: \"Sapan Tanted, Anshul Agarwal, Shinjan Mitra, Chaitra Bahuman, and Krithi Ramamritham. 2020. Database and Caching Support for Adaptive Visualization of Large Sensor Data.\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 270,\n              columnNumber: 15\n            }, this), ' ', /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 275,\n              columnNumber: 15\n            }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n              children: \"Proceedings of the 7th ACM IKDD CoDS and 25th COMAD( CoDS COMAD 2020\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 277,\n              columnNumber: 15\n            }, this), \"). Association for Computing Machinery, New York, NY, USA, 98\\u2013106. DOI:https://doi.org/10.1145/3371158.3371170\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 268,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n            trigger: \"Read More\",\n            className: \"full-text\",\n            children: /*#__PURE__*/_jsxDEV(\"p\", {\n              className: \"full-text\",\n              children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 286,\n                columnNumber: 17\n              }, this), \"The authors discuss visualization of large amounts of sensor data ( time series data) and the design, implementation and performance of an aggregation mechanism to faciliate the former task. Authors advise against displaying too many data points on a single screen as it can make the visualization slow, increase network usage and render the interface less informative and cluttered. They note that techniques like filtering, sampling and aggregation are commonly used in visualization systems to reduce the number of data points displayed. Authors state that the existing visualization systems are found to be inadequate in handling the inflow of large volumes of data. They propose a system that combines aggregation and caching techniques to implement a robust solution that helps visualization of large amounts of sensor data. Authors used Grafana as a visualization interface for their experiments since it is a widelyused open-source tool, provides data customization and allows creating dashboards with attractive visualizations. The technique proposed in this paper follows a hybrid approach where aggregation is performed on-demand, and aggregation of future requests is also taken into consideration. Thus, it requires less space for storing the aggregated data, with minimal delays experienced by users. The proposed approach is independent of the visualization tool and databases and integrates well with existing systems. \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 310,\n                columnNumber: 35\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 311,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: lit1a,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 312,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 313,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 314,\n                columnNumber: 17\n              }, this), \"One sample visualization from the project is the comparison between the power consumption of two labs - as visualizing raw data for one year is not possible, the system aggregates and visualizes the data as shown in Figure 5, which shows the power consumption of appliances (lights and fans) of two labs (lab1 - green, lab2 - orange) in the building for a period of one month. The user can zoom in to the desired section to view lower granularity data, based on the visual inspection of this graph. The visualization interface enables a smooth transition between granularities to provide rich user experience as shown in Figure 6.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 326,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 327,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: granular,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 328,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 285,\n              columnNumber: 15\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 284,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 331,\n            columnNumber: 13\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 267,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          children: /*#__PURE__*/_jsxDEV(Collapsible, {\n            trigger: \"View more Data Visualization Research paper reviews \",\n            className: \"full-text\",\n            children: [' ', /*#__PURE__*/_jsxDEV(\"div\", {\n              children: [/*#__PURE__*/_jsxDEV(\"p\", {\n                className: \"full-text\",\n                children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 341,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: \"Ivan Logre, S\\xE9bastien Mosser, and Michel Riveill. 2015. Composition challenges for sensor data visualization.\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 342,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 346,\n                  columnNumber: 19\n                }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n                  children: \"Companion Proceedings of the 14th International Conference on Modularity\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 348,\n                  columnNumber: 19\n                }, this), ' ', \"(\", /*#__PURE__*/_jsxDEV(\"i\", {\n                  children: \"MODULARITY Companion 2015\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 352,\n                  columnNumber: 20\n                }, this), \"). Association for Computing Machinery, New York, NY, USA, 25\\u201326. DOI:https://doi.org/10.1145/2735386.2735927\"]\n              }, void 0, true, {\n                fileName: _jsxFileName,\n                lineNumber: 340,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n                trigger: \"Read More\",\n                className: \"full-text\",\n                children: /*#__PURE__*/_jsxDEV(\"p\", {\n                  className: \"full-text\",\n                  children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 358,\n                    columnNumber: 21\n                  }, this), \"The paper discusses the visualization dashboards and argues that the technologies that are used to design and implement them are poor from the software engineering point of view. This paper highlights how this domain could benefit from leveraging separation of concerns and software composition paradigms to support dashboard design. In particular, the authors argue that unfortunately, the tools available to design and implement such dashboards are holistic and do not take into account the inherent modularity of this domain. Authors mention that the design and implementation of a visualization dashboard involves three roles: 1. a Requirement Engineer (RE); 2. a Data Manager (DM); 3. a Dashboard Designer (DD). \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 371,\n                    columnNumber: 46\n                  }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 372,\n                    columnNumber: 21\n                  }, this), \"According to the authors, to implement a given dashboard, one can usually use visualization widget libraries, either professional solutions such as HighChart1 and AmChart2 or community-based libraries such as D3.JS3 . Then, one will add HTML5/CSS code to structure the result. However, those widgets do not allow their integration with a lot of data format, since the development effort is put on the interaction aspect instead of the interoperability. In addition, the huge amount of available widgets (e.g., D3.js offers 235 widgets on January 2015) increase the difficulty to select a suitable visualization. There is a lack of effort in the categorization of those new visualization capabilities. According to the authors, these last two points strengthen the difficulty to cooperate with other domains, considering the gap between the conceptual role of the RE and the implementation role of the DD, and because of the incompatible constraints imposed by the chosen libraries on data format then reduce reusability. \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 390,\n                    columnNumber: 61\n                  }, this), \"This paper does not aim to describe a solution, but instead focuses on the challenges triggered by the design of visualization dashboards, and align them with modular paradigms such as separation of concerns and software composition.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 396,\n                    columnNumber: 21\n                  }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 397,\n                    columnNumber: 21\n                  }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                    src: granular,\n                    alt: \"poster gif\",\n                    className: \"vis-img\"\n                  }, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 398,\n                    columnNumber: 21\n                  }, this)]\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 357,\n                  columnNumber: 19\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 356,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 401,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 339,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              children: [/*#__PURE__*/_jsxDEV(\"p\", {\n                className: \"full-text\",\n                children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 405,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: \"Felix G. Hamza-Lup, Ionut E. Iacob, and Sushmita Khan. 2019. Web-enabled Intelligent System for Continuous Sensor Data Processing and Visualization.\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 406,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 411,\n                  columnNumber: 19\n                }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n                  children: \"The 24th International Conference on 3D Web Technology\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 413,\n                  columnNumber: 19\n                }, this), ' ', \"(\", /*#__PURE__*/_jsxDEV(\"i\", {\n                  children: \"Web3D '19\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 416,\n                  columnNumber: 20\n                }, this), \"). Association for Computing Machinery, New York, NY, USA, 1\\u20137. DOI:https://doi.org/10.1145/3329714.3338127\"]\n              }, void 0, true, {\n                fileName: _jsxFileName,\n                lineNumber: 404,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n                trigger: \"Read More\",\n                className: \"full-text\",\n                children: /*#__PURE__*/_jsxDEV(\"p\", {\n                  className: \"full-text\",\n                  children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 422,\n                    columnNumber: 21\n                  }, this), \"The authors focus on real-time data processing and 3D visualization in web-based user interfaces that facilitate spatial information understanding and sharing. In their research, they provide a prototype system for near real-time, continuous X3D-based visualization of processed sensor data for two significant applications: thermal monitoring for residential/commercial buildings and nitrogen cycle monitoring in water beds for aquaponics systems. The data processing is a three steps process: (i) collect real-time data from sensors, (ii) process the data, and (iii) visualize the information as a spatio-temporal matrix.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 434,\n                    columnNumber: 21\n                  }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 435,\n                    columnNumber: 21\n                  }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                    src: lit2a,\n                    alt: \"poster gif\",\n                    className: \"vis-img\"\n                  }, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 436,\n                    columnNumber: 21\n                  }, this)]\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 421,\n                  columnNumber: 19\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 420,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 439,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 403,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              children: [/*#__PURE__*/_jsxDEV(\"p\", {\n                className: \"full-text\",\n                children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 443,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: \"Hironobu Takagi, Chieko Asakawa, Kentarou Fukuda, and Junji Maeda. 2003. Accessibility designer: visualizing usability for the blind.\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 444,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 449,\n                  columnNumber: 19\n                }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n                  children: \"Proceedings of the 6th international ACM SIGACCESS conference on Computers and accessibility\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 451,\n                  columnNumber: 19\n                }, this), ' ', \"(\", /*#__PURE__*/_jsxDEV(\"i\", {\n                  children: \"Assets '04\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 455,\n                  columnNumber: 20\n                }, this), \"). Association for Computing Machinery, New York, NY, USA, 177\\u2013184. DOI:https://doi.org/10.1145/1028630.1028662\"]\n              }, void 0, true, {\n                fileName: _jsxFileName,\n                lineNumber: 442,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n                trigger: \"Read More\",\n                className: \"full-text\",\n                children: /*#__PURE__*/_jsxDEV(\"p\", {\n                  className: \"full-text\",\n                  children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 461,\n                    columnNumber: 21\n                  }, this), \"The authors develop Accessibility Designer (aDesigner), which has capabilities to visualize blind users' usability by using colors and gradations. The visualization function allows Web designers to grasp the weak points in their pages, and to recognize how accessible or inaccessible their pages are at a glance. This paper provides an extensive literature review and describes an approach to visualize blind users' usability followed by an overview of Accessibility Designer and also report on the evaluations of real Web sites using Accessibility Designer.\"]\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 460,\n                  columnNumber: 19\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 459,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 474,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 441,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              children: [/*#__PURE__*/_jsxDEV(\"p\", {\n                className: \"full-text\",\n                children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 478,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: [' ', \"Arne Br\\xF6ring, David Vial, and Thorsten Reitz. 2014. Processing real-time sensor data streams for 3D web visualization.\", ' ']\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 479,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 485,\n                  columnNumber: 19\n                }, this), \"In\", ' ', /*#__PURE__*/_jsxDEV(\"i\", {\n                  children: \"Proceedings of the 5th ACM SIGSPATIAL International Workshop on GeoStreaming (IWGS '14\"\n                }, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 487,\n                  columnNumber: 19\n                }, this), \"). Association for Computing Machinery, New York, NY, USA, 72\\u201380. DOI:https://doi.org/10.1145/2676552.2676556\"]\n              }, void 0, true, {\n                fileName: _jsxFileName,\n                lineNumber: 477,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n                trigger: \"Read More\",\n                className: \"full-text\",\n                children: /*#__PURE__*/_jsxDEV(\"p\", {\n                  className: \"full-text\",\n                  children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 496,\n                    columnNumber: 21\n                  }, this), \"The data streams produced by sensors often update with high frequencies, resulting in large data volumes. Being able to analyze those real-time sensor data streams requires efficient visualization techniques. The authors explore how 3D visualizations can be used to extend the available information space. More specifically, they present an approach for processing real-time sensor data streams to enable scalable Web-based 3D visualizations. Based on an event-driven architecture, the key contribution is the presentation of three processing patterns to optimize transmission of sensor data streams to 3D Web clients.\"]\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 495,\n                  columnNumber: 19\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 494,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 510,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 476,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              children: [/*#__PURE__*/_jsxDEV(\"p\", {\n                className: \"full-text\",\n                children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 514,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n                  children: [\"Optional, non-academic source: \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 516,\n                    columnNumber: 52\n                  }, this), \"Miller, Inclusive Design: How to Build Accessible Data Visualization | Betterment: 2020. https://www.betterment.com/resources/accessible-data-visualization/. Accessed: 2021.\"]\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 515,\n                  columnNumber: 19\n                }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                  fileName: _jsxFileName,\n                  lineNumber: 522,\n                  columnNumber: 19\n                }, this)]\n              }, void 0, true, {\n                fileName: _jsxFileName,\n                lineNumber: 513,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n                trigger: \"Read More\",\n                className: \"full-text\",\n                children: /*#__PURE__*/_jsxDEV(\"p\", {\n                  className: \"full-text\",\n                  children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                    fileName: _jsxFileName,\n                    lineNumber: 526,\n                    columnNumber: 21\n                  }, this), \"The author discusses common accessibility rules that developers should consider when designing a web application. Although this article is non-academic, it references official World Wide Web Consortium guidelines on web accessibility rules.\"]\n                }, void 0, true, {\n                  fileName: _jsxFileName,\n                  lineNumber: 525,\n                  columnNumber: 19\n                }, this)\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 524,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 534,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 512,\n              columnNumber: 15\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 334,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 333,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 29,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 539,\n        columnNumber: 9\n      }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 539,\n        columnNumber: 16\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"block\",\n        children: [/*#__PURE__*/_jsxDEV(\"h4\", {\n          className: \"gif-text\",\n          children: \"Sensor Data Visualization Challenges \"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 541,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          className: \"full-text\",\n          children: [\"Visualizing large amounts of temporal data requires balancing the goals of achieving high performance and interactivity. One solution lies in intelligently aggregating the data to higher granularities, so that the number of data points to be visualized is reduced and is easier for the user to interpret - view an illustration of granular visualization below. \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 548,\n            columnNumber: 34\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 549,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n            src: granular,\n            alt: \"poster gif\",\n            className: \"vis-img\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 550,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 551,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 552,\n            columnNumber: 13\n          }, this), \"Moreover, visualizing the longitudinal data such as noise or air pollution data is challenging due to continuity of the data (no precise start and end). For example, many line or bar charts that deal with the 24-hour cycle simply pick a point at which the chart starts and ends. Sometimes the charts go from 12am-12am, sometimes they use ranges like 4am-4am (which puts the break during a time when most people are sleeping). For specific data this is often acceptable, but in general it is a limitation (How can you pick an arbitrary time to break the data? How are you sure the most interesting part of the data doesn\\u2019t overlap when the chart begins and ends?)\"]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 542,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 565,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 540,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 567,\n        columnNumber: 9\n      }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 567,\n        columnNumber: 16\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"block\",\n        children: [/*#__PURE__*/_jsxDEV(\"h4\", {\n          className: \"gif-text\",\n          children: \"Visualization Graphs and Discussion \"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 569,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          children: [/*#__PURE__*/_jsxDEV(\"p\", {\n            className: \"full-text\",\n            children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 572,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"b\", {\n              children: \"Line Chart\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 573,\n              columnNumber: 15\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 571,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(Collapsible, {\n            trigger: \"Pros \",\n            className: \"full-text\",\n            children: /*#__PURE__*/_jsxDEV(\"p\", {\n              className: \"full-text\",\n              children: [\"In this paper, authors present a new approach to monitor noise pollution involving citizens who can measure their personal exposure to noise in their everyday environment by using GPS-equipped mobile phones as noise sensors. The geo-localised measures and user-generated meta-data can be automatically sent and shared online with the public to contribute to the collective noise mapping of cities. The prototype called Noise Tube can be found online. This application collects local information from different sensors (noise level, GPS coordinates, time, user input) and sends them to the NoiseTube server which visualizes the noise level data. The server centralises and processes the data sent by the phones.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 589,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 590,\n                columnNumber: 17\n              }, this), \"The mobile application contains a real-time signal processing algorithm which measures the loudness level of the microphone recording the environmental sound (at 22500 Hz, 16 bits) over 1 second at a chosen interval. On top of the sensing of the loudness a real time visualization is displayed on the phone with the decibels. To add meaning to this value it is associated with a colour that represents the health risk of the current exposure level: less than 70: green (no risk); between 70 and 80: yellow (be careful); more than 80: red (risky). See figure 2 below.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 601,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 602,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: lit2,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 603,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 604,\n                columnNumber: 17\n              }, this), \"In addition to measured loudness, the app allows to record the source or context of noise, which is not always available but remains important. Especially because the appreciation of sound and loudness is a subjective matter \\u2013 i.e. the perceived annoyance (or pleasure) does not always correlate with its loudness (see 6.2). Context is recorded through environmental tagging (source of a noise e.g.: cars, aircraft, neighbours and an annoyance rating/tag) and geo-tagging (gps positioning or place tags (such as \\u201Chome\\u201D, \\u201Cwork\\u201D, the name of the subway station, ...) Geo-tagging feature we can reconstruct the geo-coordinates afterwards notably for indoor locations (cf. subway noise map in figure 3).\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 617,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n                src: lit3,\n                alt: \"poster gif\",\n                className: \"vis-img\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 618,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 619,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 620,\n                columnNumber: 17\n              }, this), \"Visualising Noise Maps. Once the measured data is sent to the server, any user can see his own contributions or exposures by going to the NoiseTube website and visualizing them on a map thanks to Google Earth. The collective noise map is also publicly available constructed by aggregating all the shared participants. Each map can show a layer of participants to add context and meaning to the loudness data. The authors also allow users embed this as a web widget into their personal web pages and provide publicly accessible web API to give full access to third parties such scientists or developers can use individual or collective exposure data to create web mash-ups or analyse data for scientific purposes.\"]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 576,\n              columnNumber: 15\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 575,\n            columnNumber: 13\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 635,\n            columnNumber: 13\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 570,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"h6\", {\n          className: \"gif-text-h6\",\n          children: \"Line Chart \"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 637,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          className: \"full-text\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 638,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 639,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 568,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 641,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(Footer, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 643,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true);\n}\n\n_c = DataVisualization;\nexport default DataVisualization;\n\nvar _c;\n\n$RefreshReg$(_c, \"DataVisualization\");","map":{"version":3,"sources":["/Users/almazhan/Desktop/sonyc-app-ugsrp/src/pages/DataVisualization.js"],"names":["React","Header","Footer","lit1","lit2","lit3","lit4","lit5","lit1a","lit2a","granular","Collapsible","DataVisualization"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAOC,MAAP,MAAmB,sBAAnB;AACA,OAAOC,MAAP,MAAmB,sBAAnB;AACA,OAAOC,IAAP,MAAiB,oBAAjB;AACA,OAAOC,IAAP,MAAiB,oBAAjB;AACA,OAAOC,IAAP,MAAiB,oBAAjB;AACA,OAAOC,IAAP,MAAiB,oBAAjB;AACA,OAAOC,IAAP,MAAiB,oBAAjB;AACA,OAAOC,KAAP,MAAkB,qBAAlB;AACA,OAAOC,KAAP,MAAkB,qBAAlB;AACA,OAAOC,QAAP,MAAqB,wBAArB;AACA,OAAO,yBAAP;AACA,OAAOC,WAAP,MAAwB,mBAAxB;;;;AAEA,SAASC,iBAAT,GAA6B;AAC3B,sBACE;AAAA,4BACE,QAAC,MAAD;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAK,MAAA,SAAS,EAAC,MAAf;AAAA,8BACE;AAAI,QAAA,SAAS,EAAC,aAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADF,eAEE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA,gCACE;AAAG,UAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,eAME;AAAA;AAAA;AAAA;AAAA,gBANF;AAAA;AAAA;AAAA;AAAA;AAAA,cAFF,eAUE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA,gCACE;AAAI,UAAA,SAAS,EAAC,UAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,eAGE;AAAA,kCACE;AAAG,YAAA,SAAS,EAAC,WAAb;AAAA,oCACE;AAAA,yBACG,GADH;AAAA;AAAA;AAAA;AAAA;AAAA,oBADF,eAQE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBARF;AAAA;AAAA;AAAA;AAAA;AAAA,kBADF,eAgBE,QAAC,WAAD;AAAa,YAAA,OAAO,EAAC,WAArB;AAAiC,YAAA,SAAS,EAAC,WAA3C;AAAA,oCACE;AAAG,cAAA,SAAS,EAAC,WAAb;AAAA,28BAgBE;AAAA;AAAA;AAAA;AAAA,sBAhBF;AAAA;AAAA;AAAA;AAAA;AAAA,oBADF,eA4BE;AAAK,cAAA,GAAG,EAAET,IAAV;AAAgB,cAAA,GAAG,EAAC,YAApB;AAAiC,cAAA,SAAS,EAAC;AAA3C;AAAA;AAAA;AAAA;AAAA,oBA5BF;AAAA;AAAA;AAAA;AAAA;AAAA,kBAhBF,eA8CE;AAAA;AAAA;AAAA;AAAA,kBA9CF;AAAA;AAAA;AAAA;AAAA;AAAA,gBAHF,eAoDE;AAAA,kCACE;AAAG,YAAA,SAAS,EAAC,WAAb;AAAA,oCACE;AAAA;AAAA;AAAA;AAAA,oBADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAFF,QAOK,GAPL,eAQE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBARF,EAYO,GAZP,oBAaG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAbH;AAAA;AAAA;AAAA;AAAA;AAAA,kBADF,eAiBE,QAAC,WAAD;AAAa,YAAA,OAAO,EAAC,WAArB;AAAiC,YAAA,SAAS,EAAC,WAA3C;AAAA,mCACE;AAAG,cAAA,SAAS,EAAC,WAAb;AAAA,gvBAaE;AAAA;AAAA;AAAA;AAAA,sBAbF,eAcE;AAAA;AAAA;AAAA;AAAA,sBAdF,ykBAyBE;AAAA;AAAA;AAAA;AAAA,sBAzBF,eA0BE;AAAA;AAAA;AAAA;AAAA,sBA1BF,eA2BE;AAAK,gBAAA,GAAG,EAAEC,IAAV;AAAgB,gBAAA,GAAG,EAAC,YAApB;AAAiC,gBAAA,SAAS,EAAC;AAA3C;AAAA;AAAA;AAAA;AAAA,sBA3BF,eA4BE;AAAA;AAAA;AAAA;AAAA,sBA5BF,uuBAyCE;AAAA;AAAA;AAAA;AAAA,sBAzCF,eA0CE;AAAK,gBAAA,GAAG,EAAEC,IAAV;AAAgB,gBAAA,GAAG,EAAC,YAApB;AAAiC,gBAAA,SAAS,EAAC;AAA3C;AAAA;AAAA;AAAA;AAAA,sBA1CF,eA2CE;AAAA;AAAA;AAAA;AAAA,sBA3CF,eA4CE;AAAA;AAAA;AAAA;AAAA,sBA5CF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,kBAjBF,eA6EE;AAAA;AAAA;AAAA;AAAA,kBA7EF;AAAA;AAAA;AAAA;AAAA;AAAA,gBApDF,eAmIE;AAAA,kCACE;AAAG,YAAA,SAAS,EAAC,WAAb;AAAA,oCACE;AAAA;AAAA;AAAA;AAAA,oBADF,eAEE;AAAA,8KAGwB,GAHxB;AAAA;AAAA;AAAA;AAAA;AAAA,oBAFF,QAOK,GAPL,eAQE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBARF,EAWO,GAXP,oBAYG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAZH;AAAA;AAAA;AAAA;AAAA;AAAA,kBADF,eAgBE,QAAC,WAAD;AAAa,YAAA,OAAO,EAAC,WAArB;AAAiC,YAAA,SAAS,EAAC,WAA3C;AAAA,mCACE;AAAG,cAAA,SAAS,EAAC,WAAb;AAAA,w5BAegB;AAAA;AAAA;AAAA;AAAA,sBAfhB,eAgBE;AAAA;AAAA;AAAA;AAAA,sBAhBF,eAiBE;AAAK,gBAAA,GAAG,EAAEC,IAAV;AAAgB,gBAAA,GAAG,EAAC,YAApB;AAAiC,gBAAA,SAAS,EAAC;AAA3C;AAAA;AAAA;AAAA;AAAA,sBAjBF,eAkBE;AAAA;AAAA;AAAA;AAAA,sBAlBF,eAmBE;AAAA;AAAA;AAAA;AAAA,sBAnBF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,kBAhBF,eAiDE;AAAA;AAAA;AAAA;AAAA,kBAjDF;AAAA;AAAA;AAAA;AAAA;AAAA,gBAnIF,eAsLE;AAAA,kCACE;AAAG,YAAA,SAAS,EAAC,WAAb;AAAA,oCACE;AAAA;AAAA;AAAA;AAAA,oBADF,eAEE;AAAA,mLAG2B,GAH3B;AAAA;AAAA;AAAA;AAAA;AAAA,oBAFF,QAOK,GAPL,eAQE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBARF,EAWO,GAXP,oBAYG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAZH;AAAA;AAAA;AAAA;AAAA;AAAA,kBADF,eAgBE,QAAC,WAAD;AAAa,YAAA,OAAO,EAAC,WAArB;AAAiC,YAAA,SAAS,EAAC,WAA3C;AAAA,mCACE;AAAG,cAAA,SAAS,EAAC,WAAb;AAAA,opBAWE;AAAA;AAAA;AAAA;AAAA,sBAXF,eAYE;AAAA;AAAA;AAAA;AAAA,sBAZF,eAaE;AAAK,gBAAA,GAAG,EAAEC,IAAV;AAAgB,gBAAA,GAAG,EAAC,YAApB;AAAiC,gBAAA,SAAS,EAAC;AAA3C;AAAA;AAAA;AAAA;AAAA,sBAbF,eAcE;AAAA;AAAA;AAAA;AAAA,sBAdF,oBAcS;AAAA;AAAA;AAAA;AAAA,sBAdT,4jCAiCE;AAAA;AAAA;AAAA;AAAA,sBAjCF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,kBAhBF,eAqDE;AAAA;AAAA;AAAA;AAAA,kBArDF;AAAA;AAAA;AAAA;AAAA;AAAA,gBAtLF,eA8OE;AAAA,kCACE;AAAG,YAAA,SAAS,EAAC,WAAb;AAAA,oCACE;AAAA;AAAA;AAAA;AAAA,oBADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAFF,EAMO,GANP,eAOE;AAAA;AAAA;AAAA;AAAA,oBAPF,QAQK,GARL,eASE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBATF;AAAA;AAAA;AAAA;AAAA;AAAA,kBADF,eAiBE,QAAC,WAAD;AAAa,YAAA,OAAO,EAAC,WAArB;AAAiC,YAAA,SAAS,EAAC,WAA3C;AAAA,mCACE;AAAG,cAAA,SAAS,EAAC,WAAb;AAAA,sCACE;AAAA;AAAA;AAAA;AAAA,sBADF,86CAyBoB;AAAA;AAAA;AAAA;AAAA,sBAzBpB,eA0BE;AAAA;AAAA;AAAA;AAAA,sBA1BF,eA2BE;AAAK,gBAAA,GAAG,EAAEC,KAAV;AAAiB,gBAAA,GAAG,EAAC,YAArB;AAAkC,gBAAA,SAAS,EAAC;AAA5C;AAAA;AAAA;AAAA;AAAA,sBA3BF,eA4BE;AAAA;AAAA;AAAA;AAAA,sBA5BF,eA6BE;AAAA;AAAA;AAAA;AAAA,sBA7BF,yoBAyCE;AAAA;AAAA;AAAA;AAAA,sBAzCF,eA0CE;AAAA;AAAA;AAAA;AAAA,sBA1CF,eA2CE;AAAK,gBAAA,GAAG,EAAEE,QAAV;AAAoB,gBAAA,GAAG,EAAC,YAAxB;AAAqC,gBAAA,SAAS,EAAC;AAA/C;AAAA;AAAA;AAAA;AAAA,sBA3CF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,kBAjBF,eAgEE;AAAA;AAAA;AAAA;AAAA,kBAhEF;AAAA;AAAA;AAAA;AAAA;AAAA,gBA9OF,eAgTE;AAAA,iCACE,QAAC,WAAD;AACE,YAAA,OAAO,EAAC,sDADV;AAEE,YAAA,SAAS,EAAC,WAFZ;AAAA,uBAIG,GAJH,eAKE;AAAA,sCACE;AAAG,gBAAA,SAAS,EAAC,WAAb;AAAA,wCACE;AAAA;AAAA;AAAA;AAAA,wBADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAFF,eAME;AAAA;AAAA;AAAA;AAAA,wBANF,QAOK,GAPL,eAQE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBARF,EAWO,GAXP,oBAYG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAZH;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,eAiBE,QAAC,WAAD;AAAa,gBAAA,OAAO,EAAC,WAArB;AAAiC,gBAAA,SAAS,EAAC,WAA3C;AAAA,uCACE;AAAG,kBAAA,SAAS,EAAC,WAAb;AAAA,0CACE;AAAA;AAAA;AAAA;AAAA,0BADF,guBAc2B;AAAA;AAAA;AAAA;AAAA,0BAd3B,eAeE;AAAA;AAAA;AAAA;AAAA,0BAfF,ghCAiC0C;AAAA;AAAA;AAAA;AAAA,0BAjC1C,4PAuCE;AAAA;AAAA;AAAA;AAAA,0BAvCF,eAwCE;AAAA;AAAA;AAAA;AAAA,0BAxCF,eAyCE;AAAK,oBAAA,GAAG,EAAEA,QAAV;AAAoB,oBAAA,GAAG,EAAC,YAAxB;AAAqC,oBAAA,SAAS,EAAC;AAA/C;AAAA;AAAA;AAAA;AAAA,0BAzCF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,sBAjBF,eA8DE;AAAA;AAAA;AAAA;AAAA,sBA9DF;AAAA;AAAA;AAAA;AAAA;AAAA,oBALF,eAqEE;AAAA,sCACE;AAAG,gBAAA,SAAS,EAAC,WAAb;AAAA,wCACE;AAAA;AAAA;AAAA;AAAA,wBADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAFF,eAOE;AAAA;AAAA;AAAA;AAAA,wBAPF,QAQK,GARL,eASE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBATF,EAWO,GAXP,oBAYG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAZH;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,eAiBE,QAAC,WAAD;AAAa,gBAAA,OAAO,EAAC,WAArB;AAAiC,gBAAA,SAAS,EAAC,WAA3C;AAAA,uCACE;AAAG,kBAAA,SAAS,EAAC,WAAb;AAAA,0CACE;AAAA;AAAA;AAAA;AAAA,0BADF,koBAaE;AAAA;AAAA;AAAA;AAAA,0BAbF,eAcE;AAAA;AAAA;AAAA;AAAA,0BAdF,eAeE;AAAK,oBAAA,GAAG,EAAED,KAAV;AAAiB,oBAAA,GAAG,EAAC,YAArB;AAAkC,oBAAA,SAAS,EAAC;AAA5C;AAAA;AAAA;AAAA;AAAA,0BAfF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,sBAjBF,eAoCE;AAAA;AAAA;AAAA;AAAA,sBApCF;AAAA;AAAA;AAAA;AAAA;AAAA,oBArEF,eA2GE;AAAA,sCACE;AAAG,gBAAA,SAAS,EAAC,WAAb;AAAA,wCACE;AAAA;AAAA;AAAA;AAAA,wBADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAFF,eAOE;AAAA;AAAA;AAAA;AAAA,wBAPF,QAQK,GARL,eASE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBATF,EAYO,GAZP,oBAaG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAbH;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,eAkBE,QAAC,WAAD;AAAa,gBAAA,OAAO,EAAC,WAArB;AAAiC,gBAAA,SAAS,EAAC,WAA3C;AAAA,uCACE;AAAG,kBAAA,SAAS,EAAC,WAAb;AAAA,0CACE;AAAA;AAAA;AAAA;AAAA,0BADF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,sBAlBF,eAiCE;AAAA;AAAA;AAAA;AAAA,sBAjCF;AAAA;AAAA;AAAA;AAAA;AAAA,oBA3GF,eA8IE;AAAA,sCACE;AAAG,gBAAA,SAAS,EAAC,WAAb;AAAA,wCACE;AAAA;AAAA;AAAA;AAAA,wBADF,eAEE;AAAA,6BACG,GADH,+HAIiB,GAJjB;AAAA;AAAA;AAAA;AAAA;AAAA,wBAFF,eAQE;AAAA;AAAA;AAAA;AAAA,wBARF,QASK,GATL,eAUE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAVF;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,eAkBE,QAAC,WAAD;AAAa,gBAAA,OAAO,EAAC,WAArB;AAAiC,gBAAA,SAAS,EAAC,WAA3C;AAAA,uCACE;AAAG,kBAAA,SAAS,EAAC,WAAb;AAAA,0CACE;AAAA;AAAA;AAAA;AAAA,0BADF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,sBAlBF,eAkCE;AAAA;AAAA;AAAA;AAAA,sBAlCF;AAAA;AAAA;AAAA;AAAA;AAAA,oBA9IF,eAkLE;AAAA,sCACE;AAAG,gBAAA,SAAS,EAAC,WAAb;AAAA,wCACE;AAAA;AAAA;AAAA;AAAA,wBADF,eAEE;AAAA,6EACiC;AAAA;AAAA;AAAA;AAAA,0BADjC;AAAA;AAAA;AAAA;AAAA;AAAA,wBAFF,eASE;AAAA;AAAA;AAAA;AAAA,wBATF;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,eAYE,QAAC,WAAD;AAAa,gBAAA,OAAO,EAAC,WAArB;AAAiC,gBAAA,SAAS,EAAC,WAA3C;AAAA,uCACE;AAAG,kBAAA,SAAS,EAAC,WAAb;AAAA,0CACE;AAAA;AAAA;AAAA;AAAA,0BADF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,sBAZF,eAsBE;AAAA;AAAA;AAAA;AAAA,sBAtBF;AAAA;AAAA;AAAA;AAAA;AAAA,oBAlLF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,gBAhTF;AAAA;AAAA;AAAA;AAAA;AAAA,cAVF,eAwgBE;AAAA;AAAA;AAAA;AAAA,cAxgBF,oBAwgBS;AAAA;AAAA;AAAA;AAAA,cAxgBT,eAygBE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA,gCACE;AAAI,UAAA,SAAS,EAAC,UAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,eAEE;AAAG,UAAA,SAAS,EAAC,WAAb;AAAA,8YAMuB;AAAA;AAAA;AAAA;AAAA,kBANvB,eAOE;AAAA;AAAA;AAAA;AAAA,kBAPF,eAQE;AAAK,YAAA,GAAG,EAAEC,QAAV;AAAoB,YAAA,GAAG,EAAC,YAAxB;AAAqC,YAAA,SAAS,EAAC;AAA/C;AAAA;AAAA;AAAA;AAAA,kBARF,eASE;AAAA;AAAA;AAAA;AAAA,kBATF,eAUE;AAAA;AAAA;AAAA;AAAA,kBAVF;AAAA;AAAA;AAAA;AAAA;AAAA,gBAFF,eAyBE;AAAA;AAAA;AAAA;AAAA,gBAzBF;AAAA;AAAA;AAAA;AAAA;AAAA,cAzgBF,eAoiBE;AAAA;AAAA;AAAA;AAAA,cApiBF,oBAoiBS;AAAA;AAAA;AAAA;AAAA,cApiBT,eAqiBE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA,gCACE;AAAI,UAAA,SAAS,EAAC,UAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,eAEE;AAAA,kCACE;AAAG,YAAA,SAAS,EAAC,WAAb;AAAA,oCACE;AAAA;AAAA;AAAA;AAAA,oBADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAFF;AAAA;AAAA;AAAA;AAAA;AAAA,kBADF,eAKE,QAAC,WAAD;AAAa,YAAA,OAAO,EAAC,OAArB;AAA6B,YAAA,SAAS,EAAC,WAAvC;AAAA,mCACE;AAAG,cAAA,SAAS,EAAC,WAAb;AAAA,gvBAaE;AAAA;AAAA;AAAA;AAAA,sBAbF,eAcE;AAAA;AAAA;AAAA;AAAA,sBAdF,ykBAyBE;AAAA;AAAA;AAAA;AAAA,sBAzBF,eA0BE;AAAA;AAAA;AAAA;AAAA,sBA1BF,eA2BE;AAAK,gBAAA,GAAG,EAAEN,IAAV;AAAgB,gBAAA,GAAG,EAAC,YAApB;AAAiC,gBAAA,SAAS,EAAC;AAA3C;AAAA;AAAA;AAAA;AAAA,sBA3BF,eA4BE;AAAA;AAAA;AAAA;AAAA,sBA5BF,uuBAyCE;AAAA;AAAA;AAAA;AAAA,sBAzCF,eA0CE;AAAK,gBAAA,GAAG,EAAEC,IAAV;AAAgB,gBAAA,GAAG,EAAC,YAApB;AAAiC,gBAAA,SAAS,EAAC;AAA3C;AAAA;AAAA;AAAA;AAAA,sBA1CF,eA2CE;AAAA;AAAA;AAAA;AAAA,sBA3CF,eA4CE;AAAA;AAAA;AAAA;AAAA,sBA5CF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,kBALF,eAiEE;AAAA;AAAA;AAAA;AAAA,kBAjEF;AAAA;AAAA;AAAA;AAAA;AAAA,gBAFF,eAqEE;AAAI,UAAA,SAAS,EAAC,aAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBArEF,eAsEE;AAAG,UAAA,SAAS,EAAC;AAAb;AAAA;AAAA;AAAA;AAAA,gBAtEF,eAuEE;AAAA;AAAA;AAAA;AAAA,gBAvEF;AAAA;AAAA;AAAA;AAAA;AAAA,cAriBF,eA8mBE;AAAA;AAAA;AAAA;AAAA,cA9mBF;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF,eAknBE,QAAC,MAAD;AAAA;AAAA;AAAA;AAAA,YAlnBF;AAAA,kBADF;AAsnBD;;KAvnBQO,iB;AAynBT,eAAeA,iBAAf","sourcesContent":["import React from 'react'\nimport Header from '../components/Header'\nimport Footer from '../components/Footer'\nimport lit1 from '../images/lit1.png'\nimport lit2 from '../images/lit2.png'\nimport lit3 from '../images/lit3.png'\nimport lit4 from '../images/lit4.png'\nimport lit5 from '../images/lit5.png'\nimport lit1a from '../images/lit1a.png'\nimport lit2a from '../images/lit2a.png'\nimport granular from '../images/granular.png'\nimport './DataVisualization.css'\nimport Collapsible from 'react-collapsible'\n\nfunction DataVisualization() {\n  return (\n    <>\n      <Header />\n      <div className=\"home\">\n        <h2 className=\"header-text\">Data Visualization</h2>\n        <div className=\"block\">\n          <p className=\"full-text\">\n            Sensors are used to measure air and noise pollution levels and\n            visualizing the data is the first step in making decisions about the\n            data.\n          </p>\n          <br />\n        </div>\n        <div className=\"block\">\n          <h4 className=\"gif-text\">Data Visualization Research Review</h4>\n\n          <div>\n            <p className=\"full-text\">\n              <b>\n                {' '}\n                Guess the Data: Data Work to Understand How People Make Sense of\n                and Use Simple Sensor Data from Homes .Albrecht Kurze, Andreas\n                Bischof, Sören Totzauer, Michael Storz, Maximilian Eibl, Margot\n                Brereton, and Arne Berger. 2020.\n              </b>\n              <i>\n                Proceedings of the 2020 CHI Conference on Human Factors in\n                Computing Systems\n              </i>\n              . Association for Computing Machinery, New York, NY, USA, 1–12.\n              DOI:https://doi.org/10.1145/3313831.3376273\n            </p>\n            <Collapsible trigger=\"Read More\" className=\"full-text\">\n              <p className=\"full-text\">\n                The authors investigate human sensemaking of such sensor data\n                can reveal domestic activities and to achieve that task, develop\n                and field-test the Guess the data method,which enabled people to\n                use and make sense of live data from their homes and to\n                collectively interpret and reflect on anonymized data from the\n                homes in the study. The authors decided to use simple line\n                graphs as data visualizations for temperature, light level,\n                humidity, barometric pressure and movement (accelerometer\n                values). They wanted to undertake very little pre-processing,\n                presenting close to ‘raw’ data, to prevent interpretation bias.\n                Such simple time series graphs are comparable to those used in\n                other cited studies. The findings show how participants\n                reconstruct behavior, both individually and collectively, expose\n                the sensitive personal data of others, and use sensor data as\n                evidence and for lateral surveillance within the household.\n                <br />\n                Visualized sensor data used as evidence and proof: Participants\n                used visualized data to confirm their assumptions about other\n                residents’ behavior, not only retrospectively during discussions\n                but also pro-actively during data collection when they had\n                access to it. For example, a participant corrected the partner’s\n                careless behavior regarding the light in the hallway (figure 3),\n                which he often forgot to turn off. She confronted him with the\n                visualization of the light sensor data, and “he was a little bit\n                shocked” (II.A)\n              </p>\n              <img src={lit1} alt=\"poster gif\" className=\"vis-img\" />\n            </Collapsible>\n            <br />\n          </div>\n\n          <div>\n            <p className=\"full-text\">\n              <br />\n              <b>\n                Nicolas Maisonneuve, Matthias Stevens, Maria E. Niessen, Peter\n                Hanappe, and Luc Steels. 2009. Citizen noise pollution\n                monitoring.\n              </b>\n              In{' '}\n              <i>\n                Proceedings of the 10th Annual International Conference on\n                Digital Government Research: Social Networks: Making Connections\n                between Citizens, Data and Government\n              </i>{' '}\n              (<i>dg.o '09</i>). Digital Government Society of North America,\n              96–103. https://dl.acm.org/doi/10.5555/1556176.1556198\n            </p>\n            <Collapsible trigger=\"Read More\" className=\"full-text\">\n              <p className=\"full-text\">\n                In this paper, authors present a new approach to monitor noise\n                pollution involving citizens who can measure their personal\n                exposure to noise in their everyday environment by using\n                GPS-equipped mobile phones as noise sensors. The geo-localised\n                measures and user-generated meta-data can be automatically sent\n                and shared online with the public to contribute to the\n                collective noise mapping of cities. The prototype called Noise\n                Tube can be found online. This application collects local\n                information from different sensors (noise level, GPS\n                coordinates, time, user input) and sends them to the NoiseTube\n                server which visualizes the noise level data. The server\n                centralises and processes the data sent by the phones.\n                <br />\n                <br />\n                The mobile application contains a real-time signal processing\n                algorithm which measures the loudness level of the microphone\n                recording the environmental sound (at 22500 Hz, 16 bits) over 1\n                second at a chosen interval. On top of the sensing of the\n                loudness a real time visualization is displayed on the phone\n                with the decibels. To add meaning to this value it is associated\n                with a colour that represents the health risk of the current\n                exposure level: less than 70: green (no risk); between 70 and\n                80: yellow (be careful); more than 80: red (risky). See figure 2\n                below.\n                <br />\n                <br />\n                <img src={lit2} alt=\"poster gif\" className=\"vis-img\" />\n                <br />\n                In addition to measured loudness, the app allows to record the\n                source or context of noise, which is not always available but\n                remains important. Especially because the appreciation of sound\n                and loudness is a subjective matter – i.e. the perceived\n                annoyance (or pleasure) does not always correlate with its\n                loudness (see 6.2). Context is recorded through environmental\n                tagging (source of a noise e.g.: cars, aircraft, neighbours and\n                an annoyance rating/tag) and geo-tagging (gps positioning or\n                place tags (such as “home”, “work”, the name of the subway\n                station, ...) Geo-tagging feature we can reconstruct the\n                geo-coordinates afterwards notably for indoor locations (cf.\n                subway noise map in figure 3).\n                <br />\n                <img src={lit3} alt=\"poster gif\" className=\"vis-img\" />\n                <br />\n                <br />\n                Visualising Noise Maps. Once the measured data is sent to the\n                server, any user can see his own contributions or exposures by\n                going to the NoiseTube website and visualizing them on a map\n                thanks to Google Earth. The collective noise map is also\n                publicly available constructed by aggregating all the shared\n                participants. Each map can show a layer of participants to add\n                context and meaning to the loudness data. The authors also allow\n                users embed this as a web widget into their personal web pages\n                and provide publicly accessible web API to give full access to\n                third parties such scientists or developers can use individual\n                or collective exposure data to create web mash-ups or analyse\n                data for scientific purposes.\n              </p>\n            </Collapsible>\n            <br />\n          </div>\n          <div>\n            <p className=\"full-text\">\n              <br />\n              <b>\n                Silvia Santini, Benedikt Ostermaier, and Andrea Vitaletti. 2008.\n                First experiences using wireless sensor networks for noise\n                pollution monitoring.{' '}\n              </b>\n              In{' '}\n              <i>\n                Proceedings of the workshop on Real-world wireless sensor\n                networks\n              </i>{' '}\n              (<i>REALWSN '08</i>). Association for Computing Machinery, New\n              York, NY, USA, 61–65. DOI:https://doi.org/10.1145/1435473.1435490\n            </p>\n            <Collapsible trigger=\"Read More\" className=\"full-text\">\n              <p className=\"full-text\">\n                The authors focus on the assessment of environmental noise\n                pollution in urban areas and provide a feasibility analysis of\n                wireless sensor networks. They also present a prototype for the\n                collection and logging of noise pollution data based on the\n                Tmote invent prototyping platform, using which they performed\n                indoor and outdoor noise pollution measurements. They also\n                present tinyLAB, a Matlab-based tool developed in the context of\n                this work, which enables real-time acquisition, processing and\n                visualization of data collected in wireless sensor networks.\n                Authors mention that prototyping wireless sensor network\n                applications often requires visualizing the sensor data to\n                quickly identify any malfunctioning. For example, figure 1 shows\n                the responses to these acoustic events of four different nodes,\n                clearly pointing out a misalignment in the measured equivalent\n                noise levels. <br />\n                <br />\n                <img src={lit4} alt=\"poster gif\" className=\"vis-img\" />\n                <br />\n                <br />\n                Additionally, authors mention that current tools often do not\n                provide satisfactory data processing and visualization features\n                and propose using Matlab as it serves scientists in managing,\n                processing and visualizing their data and appears therefore\n                particularly well-suited to be used in the context of wireless\n                sensor networks. Authors develop tinyLAB, a simple framework\n                that allows to receive and send messages from and to a sensor\n                network and to visualize and process data as it comes from the\n                network. tinyLAB is implemented relying solely on the Matlab\n                software suite and offers a simple API to receive and send data.\n              </p>\n            </Collapsible>\n            <br />\n          </div>\n          <div>\n            <p className=\"full-text\">\n              <br />\n              <b>\n                Ann-sofie Gunnarsson, Malinda Rauhala, Anders Henrysson, and\n                Anders Ynnerman. 2006. Visualization of sensor data using mobile\n                phone augmented reality.{' '}\n              </b>\n              In{' '}\n              <i>\n                Proceedings of the 5th IEEE and ACM International Symposium on\n                Mixed and Augmented Reality\n              </i>{' '}\n              (<i>ISMAR '06</i>). IEEE Computer Society, USA, 233–234.\n              DOI:https://doi.org/10.1109/ISMAR.2006.297820\n            </p>\n            <Collapsible trigger=\"Read More\" className=\"full-text\">\n              <p className=\"full-text\">\n                The authors developed a prototype system for visual inspection\n                of hidden structures using a mobile phone wireless ZigBee sensor\n                network. Data collected from an embedded wireless sensor matrix\n                is used to synthesize AR visualizations in real-time. The AR\n                visualization is providing the user with an instant insight\n                concerning the status of the element being augmented. The\n                authors arrange sensors in a grid (e.g. a matrix), which allows\n                to take an approach where individual sensors emerge as pixels in\n                an image when their data is translated into color values. See\n                below an image that shows a mobile application overview.\n                <br />\n                <br />\n                <img src={lit5} alt=\"poster gif\" className=\"vis-img\" />\n                <br /> <br />\n                Authors argue that AR is an ideal way to present such context\n                related visualizations since it eliminates the focus switching\n                between the visualization domain (image) and problem domain\n                (real world). The sensors measure the relative humidity (RH) at\n                the location of the sensor, providing with data from a discrete\n                set of measure points in 3D. The values between the measure\n                points are interpolated creating a continuous visualization\n                which provides the user an overview of the humidity values as\n                well as their distribution. The mobile phone application\n                contains a visualization engine and a communication layer. The\n                interpolation is performed in real time and every time a new\n                sensor value is retrieved from the sensor network the\n                visualization is updated. Two visualization options are\n                implemented, one fully continuous, see Figure below, while the\n                other is composed of small quadratic units, separated using full\n                transparency. Authors believe that the user experiences a better\n                sense of orientation when less background information is covered\n                by the visualization.\n                <br />\n              </p>\n            </Collapsible>\n            <br />\n          </div>\n\n          <div>\n            <p className=\"full-text\">\n              <br />\n              <b>\n                Sapan Tanted, Anshul Agarwal, Shinjan Mitra, Chaitra Bahuman,\n                and Krithi Ramamritham. 2020. Database and Caching Support for\n                Adaptive Visualization of Large Sensor Data.\n              </b>{' '}\n              <br />\n              In{' '}\n              <i>\n                Proceedings of the 7th ACM IKDD CoDS and 25th COMAD( CoDS COMAD\n                2020\n              </i>\n              ). Association for Computing Machinery, New York, NY, USA, 98–106.\n              DOI:https://doi.org/10.1145/3371158.3371170\n            </p>\n            <Collapsible trigger=\"Read More\" className=\"full-text\">\n              <p className=\"full-text\">\n                <br />\n                The authors discuss visualization of large amounts of sensor\n                data ( time series data) and the design, implementation and\n                performance of an aggregation mechanism to faciliate the former\n                task. Authors advise against displaying too many data points on\n                a single screen as it can make the visualization slow, increase\n                network usage and render the interface less informative and\n                cluttered. They note that techniques like filtering, sampling\n                and aggregation are commonly used in visualization systems to\n                reduce the number of data points displayed. Authors state that\n                the existing visualization systems are found to be inadequate in\n                handling the inflow of large volumes of data. They propose a\n                system that combines aggregation and caching techniques to\n                implement a robust solution that helps visualization of large\n                amounts of sensor data. Authors used Grafana as a visualization\n                interface for their experiments since it is a widelyused\n                open-source tool, provides data customization and allows\n                creating dashboards with attractive visualizations. The\n                technique proposed in this paper follows a hybrid approach where\n                aggregation is performed on-demand, and aggregation of future\n                requests is also taken into consideration. Thus, it requires\n                less space for storing the aggregated data, with minimal delays\n                experienced by users. The proposed approach is independent of\n                the visualization tool and databases and integrates well with\n                existing systems. <br />\n                <br />\n                <img src={lit1a} alt=\"poster gif\" className=\"vis-img\" />\n                <br />\n                <br />\n                One sample visualization from the project is the comparison\n                between the power consumption of two labs - as visualizing raw\n                data for one year is not possible, the system aggregates and\n                visualizes the data as shown in Figure 5, which shows the power\n                consumption of appliances (lights and fans) of two labs (lab1 -\n                green, lab2 - orange) in the building for a period of one month.\n                The user can zoom in to the desired section to view lower\n                granularity data, based on the visual inspection of this graph.\n                The visualization interface enables a smooth transition between\n                granularities to provide rich user experience as shown in Figure\n                6.\n                <br />\n                <br />\n                <img src={granular} alt=\"poster gif\" className=\"vis-img\" />\n              </p>\n            </Collapsible>\n            <br />\n          </div>\n          <div>\n            <Collapsible\n              trigger=\"View more Data Visualization Research paper reviews \"\n              className=\"full-text\"\n            >\n              {' '}\n              <div>\n                <p className=\"full-text\">\n                  <br />\n                  <b>\n                    Ivan Logre, Sébastien Mosser, and Michel Riveill. 2015.\n                    Composition challenges for sensor data visualization.\n                  </b>\n                  <br />\n                  In{' '}\n                  <i>\n                    Companion Proceedings of the 14th International Conference\n                    on Modularity\n                  </i>{' '}\n                  (<i>MODULARITY Companion 2015</i>). Association for Computing\n                  Machinery, New York, NY, USA, 25–26.\n                  DOI:https://doi.org/10.1145/2735386.2735927\n                </p>\n                <Collapsible trigger=\"Read More\" className=\"full-text\">\n                  <p className=\"full-text\">\n                    <br />\n                    The paper discusses the visualization dashboards and argues\n                    that the technologies that are used to design and implement\n                    them are poor from the software engineering point of view.\n                    This paper highlights how this domain could benefit from\n                    leveraging separation of concerns and software composition\n                    paradigms to support dashboard design. In particular, the\n                    authors argue that unfortunately, the tools available to\n                    design and implement such dashboards are holistic and do not\n                    take into account the inherent modularity of this domain.\n                    Authors mention that the design and implementation of a\n                    visualization dashboard involves three roles: 1. a\n                    Requirement Engineer (RE); 2. a Data Manager (DM); 3. a\n                    Dashboard Designer (DD). <br />\n                    <br />\n                    According to the authors, to implement a given dashboard,\n                    one can usually use visualization widget libraries, either\n                    professional solutions such as HighChart1 and AmChart2 or\n                    community-based libraries such as D3.JS3 . Then, one will\n                    add HTML5/CSS code to structure the result. However, those\n                    widgets do not allow their integration with a lot of data\n                    format, since the development effort is put on the\n                    interaction aspect instead of the interoperability. In\n                    addition, the huge amount of available widgets (e.g., D3.js\n                    offers 235 widgets on January 2015) increase the difficulty\n                    to select a suitable visualization. There is a lack of\n                    effort in the categorization of those new visualization\n                    capabilities. According to the authors, these last two\n                    points strengthen the difficulty to cooperate with other\n                    domains, considering the gap between the conceptual role of\n                    the RE and the implementation role of the DD, and because of\n                    the incompatible constraints imposed by the chosen libraries\n                    on data format then reduce reusability. <br />\n                    This paper does not aim to describe a solution, but instead\n                    focuses on the challenges triggered by the design of\n                    visualization dashboards, and align them with modular\n                    paradigms such as separation of concerns and software\n                    composition.\n                    <br />\n                    <br />\n                    <img src={granular} alt=\"poster gif\" className=\"vis-img\" />\n                  </p>\n                </Collapsible>\n                <br />\n              </div>\n              <div>\n                <p className=\"full-text\">\n                  <br />\n                  <b>\n                    Felix G. Hamza-Lup, Ionut E. Iacob, and Sushmita Khan. 2019.\n                    Web-enabled Intelligent System for Continuous Sensor Data\n                    Processing and Visualization.\n                  </b>\n                  <br />\n                  In{' '}\n                  <i>\n                    The 24th International Conference on 3D Web Technology\n                  </i>{' '}\n                  (<i>Web3D '19</i>). Association for Computing Machinery, New\n                  York, NY, USA, 1–7.\n                  DOI:https://doi.org/10.1145/3329714.3338127\n                </p>\n                <Collapsible trigger=\"Read More\" className=\"full-text\">\n                  <p className=\"full-text\">\n                    <br />\n                    The authors focus on real-time data processing and 3D\n                    visualization in web-based user interfaces that facilitate\n                    spatial information understanding and sharing. In their\n                    research, they provide a prototype system for near\n                    real-time, continuous X3D-based visualization of processed\n                    sensor data for two significant applications: thermal\n                    monitoring for residential/commercial buildings and nitrogen\n                    cycle monitoring in water beds for aquaponics systems. The\n                    data processing is a three steps process: (i) collect\n                    real-time data from sensors, (ii) process the data, and\n                    (iii) visualize the information as a spatio-temporal matrix.\n                    <br />\n                    <br />\n                    <img src={lit2a} alt=\"poster gif\" className=\"vis-img\" />\n                  </p>\n                </Collapsible>\n                <br />\n              </div>\n              <div>\n                <p className=\"full-text\">\n                  <br />\n                  <b>\n                    Hironobu Takagi, Chieko Asakawa, Kentarou Fukuda, and Junji\n                    Maeda. 2003. Accessibility designer: visualizing usability\n                    for the blind.\n                  </b>\n                  <br />\n                  In{' '}\n                  <i>\n                    Proceedings of the 6th international ACM SIGACCESS\n                    conference on Computers and accessibility\n                  </i>{' '}\n                  (<i>Assets '04</i>). Association for Computing Machinery, New\n                  York, NY, USA, 177–184.\n                  DOI:https://doi.org/10.1145/1028630.1028662\n                </p>\n                <Collapsible trigger=\"Read More\" className=\"full-text\">\n                  <p className=\"full-text\">\n                    <br />\n                    The authors develop Accessibility Designer (aDesigner),\n                    which has capabilities to visualize blind users' usability\n                    by using colors and gradations. The visualization function\n                    allows Web designers to grasp the weak points in their\n                    pages, and to recognize how accessible or inaccessible their\n                    pages are at a glance. This paper provides an extensive\n                    literature review and describes an approach to visualize\n                    blind users' usability followed by an overview of\n                    Accessibility Designer and also report on the evaluations of\n                    real Web sites using Accessibility Designer.\n                  </p>\n                </Collapsible>\n                <br />\n              </div>\n              <div>\n                <p className=\"full-text\">\n                  <br />\n                  <b>\n                    {' '}\n                    Arne Bröring, David Vial, and Thorsten Reitz. 2014.\n                    Processing real-time sensor data streams for 3D web\n                    visualization.{' '}\n                  </b>\n                  <br />\n                  In{' '}\n                  <i>\n                    Proceedings of the 5th ACM SIGSPATIAL International Workshop\n                    on GeoStreaming (IWGS '14\n                  </i>\n                  ). Association for Computing Machinery, New York, NY, USA,\n                  72–80. DOI:https://doi.org/10.1145/2676552.2676556\n                </p>\n                <Collapsible trigger=\"Read More\" className=\"full-text\">\n                  <p className=\"full-text\">\n                    <br />\n                    The data streams produced by sensors often update with high\n                    frequencies, resulting in large data volumes. Being able to\n                    analyze those real-time sensor data streams requires\n                    efficient visualization techniques. The authors explore how\n                    3D visualizations can be used to extend the available\n                    information space. More specifically, they present an\n                    approach for processing real-time sensor data streams to\n                    enable scalable Web-based 3D visualizations. Based on an\n                    event-driven architecture, the key contribution is the\n                    presentation of three processing patterns to optimize\n                    transmission of sensor data streams to 3D Web clients.\n                  </p>\n                </Collapsible>\n                <br />\n              </div>\n              <div>\n                <p className=\"full-text\">\n                  <br />\n                  <b>\n                    Optional, non-academic source: <br />\n                    Miller, Inclusive Design: How to Build Accessible Data\n                    Visualization | Betterment: 2020.\n                    https://www.betterment.com/resources/accessible-data-visualization/.\n                    Accessed: 2021.\n                  </b>\n                  <br />\n                </p>\n                <Collapsible trigger=\"Read More\" className=\"full-text\">\n                  <p className=\"full-text\">\n                    <br />\n                    The author discusses common accessibility rules that\n                    developers should consider when designing a web application.\n                    Although this article is non-academic, it references\n                    official World Wide Web Consortium guidelines on web\n                    accessibility rules.\n                  </p>\n                </Collapsible>\n                <br />\n              </div>\n            </Collapsible>\n          </div>\n        </div>\n        <br /> <br />\n        <div className=\"block\">\n          <h4 className=\"gif-text\">Sensor Data Visualization Challenges </h4>\n          <p className=\"full-text\">\n            Visualizing large amounts of temporal data requires balancing the\n            goals of achieving high performance and interactivity. One solution\n            lies in intelligently aggregating the data to higher granularities,\n            so that the number of data points to be visualized is reduced and is\n            easier for the user to interpret - view an illustration of granular\n            visualization below. <br />\n            <br />\n            <img src={granular} alt=\"poster gif\" className=\"vis-img\" />\n            <br />\n            <br />\n            Moreover, visualizing the longitudinal data such as noise or air\n            pollution data is challenging due to continuity of the data (no\n            precise start and end). For example, many line or bar charts that\n            deal with the 24-hour cycle simply pick a point at which the chart\n            starts and ends. Sometimes the charts go from 12am-12am, sometimes\n            they use ranges like 4am-4am (which puts the break during a time\n            when most people are sleeping). For specific data this is often\n            acceptable, but in general it is a limitation (How can you pick an\n            arbitrary time to break the data? How are you sure the most\n            interesting part of the data doesn’t overlap when the chart begins\n            and ends?)\n          </p>\n          <br />\n        </div>\n        <br /> <br />\n        <div className=\"block\">\n          <h4 className=\"gif-text\">Visualization Graphs and Discussion </h4>\n          <div>\n            <p className=\"full-text\">\n              <br />\n              <b>Line Chart</b>\n            </p>\n            <Collapsible trigger=\"Pros \" className=\"full-text\">\n              <p className=\"full-text\">\n                In this paper, authors present a new approach to monitor noise\n                pollution involving citizens who can measure their personal\n                exposure to noise in their everyday environment by using\n                GPS-equipped mobile phones as noise sensors. The geo-localised\n                measures and user-generated meta-data can be automatically sent\n                and shared online with the public to contribute to the\n                collective noise mapping of cities. The prototype called Noise\n                Tube can be found online. This application collects local\n                information from different sensors (noise level, GPS\n                coordinates, time, user input) and sends them to the NoiseTube\n                server which visualizes the noise level data. The server\n                centralises and processes the data sent by the phones.\n                <br />\n                <br />\n                The mobile application contains a real-time signal processing\n                algorithm which measures the loudness level of the microphone\n                recording the environmental sound (at 22500 Hz, 16 bits) over 1\n                second at a chosen interval. On top of the sensing of the\n                loudness a real time visualization is displayed on the phone\n                with the decibels. To add meaning to this value it is associated\n                with a colour that represents the health risk of the current\n                exposure level: less than 70: green (no risk); between 70 and\n                80: yellow (be careful); more than 80: red (risky). See figure 2\n                below.\n                <br />\n                <br />\n                <img src={lit2} alt=\"poster gif\" className=\"vis-img\" />\n                <br />\n                In addition to measured loudness, the app allows to record the\n                source or context of noise, which is not always available but\n                remains important. Especially because the appreciation of sound\n                and loudness is a subjective matter – i.e. the perceived\n                annoyance (or pleasure) does not always correlate with its\n                loudness (see 6.2). Context is recorded through environmental\n                tagging (source of a noise e.g.: cars, aircraft, neighbours and\n                an annoyance rating/tag) and geo-tagging (gps positioning or\n                place tags (such as “home”, “work”, the name of the subway\n                station, ...) Geo-tagging feature we can reconstruct the\n                geo-coordinates afterwards notably for indoor locations (cf.\n                subway noise map in figure 3).\n                <br />\n                <img src={lit3} alt=\"poster gif\" className=\"vis-img\" />\n                <br />\n                <br />\n                Visualising Noise Maps. Once the measured data is sent to the\n                server, any user can see his own contributions or exposures by\n                going to the NoiseTube website and visualizing them on a map\n                thanks to Google Earth. The collective noise map is also\n                publicly available constructed by aggregating all the shared\n                participants. Each map can show a layer of participants to add\n                context and meaning to the loudness data. The authors also allow\n                users embed this as a web widget into their personal web pages\n                and provide publicly accessible web API to give full access to\n                third parties such scientists or developers can use individual\n                or collective exposure data to create web mash-ups or analyse\n                data for scientific purposes.\n              </p>\n            </Collapsible>\n            <br />\n          </div>\n          <h6 className=\"gif-text-h6\">Line Chart </h6>\n          <p className=\"full-text\"></p>\n          <br />\n        </div>\n        <br />\n      </div>\n      <Footer />\n    </>\n  )\n}\n\nexport default DataVisualization\n"]},"metadata":{},"sourceType":"module"}